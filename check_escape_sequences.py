# Initially generated by GitHub Copilot.
"""
Check that .py files do not use \\uXXXX escape sequences for characters
that are perfectly displayable as literal UTF-8 in an editor.

Characters that should appear literally include em dash (—), en dash (–),
degree sign (°), multiplication sign (×), box-drawing characters,
arrows, check marks, Hebrew letters, and Hebrew punctuation.

Characters that SHOULD remain as escapes (visually ambiguous or invisible):
  - Combining marks: CGJ (U+034F), Hebrew points/accents (U+0591–U+05C7),
    Varika (U+FB1E)
  - Zero-width / space characters: ZWJ (U+200D), NBSP, thin space, hair space
  - Any character where the literal glyph is easily confused with ASCII

Also exempt:
  - \\uXXXX inside raw strings (r"..." / r'...') — needed for regex patterns
  - \\uXXXX inside comments that document codepoints (e.g. "# U+05D9 yod")
  - pycmn/ files — these are definition files copied from book-of-job
  - The regex shown in docstrings (WORD_RE = r"[\\u0590-...")

The "word" regex for this check:

    ESCAPE_RE = r'\\u[0-9A-Fa-f]{4}'

i.e. a literal backslash, letter u, then exactly four hex digits.

Exit codes:
  0 – All files pass
  1 – One or more unnecessary escapes found
"""

import re
import sys
from pathlib import Path

# ── the escape pattern ───────────────────────────────────────────────

ESCAPE_RE = re.compile(r"\\u([0-9A-Fa-f]{4})")

# ── characters that should STAY as escapes ───────────────────────────
# Combining marks, zero-width chars, whitespace oddities.

_KEEP_AS_ESCAPE = set()

# Hebrew combining marks (Mn category only, not punctuation):
#   U+0591–U+05BD  accents & points
#   U+05BF         rafe
#   U+05C1–U+05C2  shin dot, sin dot
#   U+05C4–U+05C5  upper dot, lower dot
#   U+05C7         qamats qatan
# Excludes displayable punctuation: maqaf (U+05BE), paseq (U+05C0),
# sof pasuq (U+05C3), nun hafukha (U+05C6).
_KEEP_AS_ESCAPE.update(range(0x0591, 0x05BE))  # U+0591 – U+05BD
_KEEP_AS_ESCAPE.add(0x05BF)  # rafe
_KEEP_AS_ESCAPE.update(range(0x05C1, 0x05C3))  # shin dot, sin dot
_KEEP_AS_ESCAPE.update(range(0x05C4, 0x05C6))  # upper dot, lower dot
_KEEP_AS_ESCAPE.add(0x05C7)  # qamats qatan

# Combining Grapheme Joiner
_KEEP_AS_ESCAPE.add(0x034F)

# Varika
_KEEP_AS_ESCAPE.add(0xFB1E)

# Zero-width characters
_KEEP_AS_ESCAPE.add(0x200D)  # ZWJ
_KEEP_AS_ESCAPE.add(0x200C)  # ZWNJ
_KEEP_AS_ESCAPE.add(0xFEFF)  # BOM / ZWNBSP

# Whitespace that looks like a normal space
_KEEP_AS_ESCAPE.add(0x00A0)  # NBSP
_KEEP_AS_ESCAPE.add(0x2009)  # thin space
_KEEP_AS_ESCAPE.add(0x200A)  # hair space
_KEEP_AS_ESCAPE.add(0x202F)  # narrow no-break space
_KEEP_AS_ESCAPE.add(0x2007)  # figure space
_KEEP_AS_ESCAPE.add(0x2008)  # punctuation space

# ASCII range — \u00XX for control chars etc. are fine as escapes
_KEEP_AS_ESCAPE.update(range(0x0000, 0x0080))


def _should_be_literal(codepoint):
    """Return True if this codepoint should appear as a literal character."""
    return codepoint not in _KEEP_AS_ESCAPE


# ── raw-string detection ─────────────────────────────────────────────


def _raw_string_spans(source_line):
    """Return list of (start, end) spans that are inside raw strings."""
    spans = []
    # Simple approach: find r"..." and r'...' on each line
    for m in re.finditer(r"""r(\"\"\"|\'''|\"|')(.*?)\1""", source_line):
        spans.append((m.start(), m.end()))
    return spans


def _in_raw_string(col, spans):
    """Return True if column position is inside any raw-string span."""
    return any(start <= col < end for start, end in spans)


def _is_docstring_regex_example(line):
    """Return True if the line is a docstring showing a regex pattern."""
    stripped = line.strip()
    return stripped.startswith("WORD_RE") and 'r"' in stripped


# ── file discovery ───────────────────────────────────────────────────

_SKIP_DIRS = {".venv", "__pycache__", ".novc", ".git", "node_modules"}
_SKIP_PREFIXES = {"pycmn"}  # definition files copied from book-of-job


def _tracked_files(root):
    """Yield .py paths under *root*, skipping non-tracked dirs and pycmn."""
    for p in sorted(root.rglob("*.py")):
        if any(part in _SKIP_DIRS for part in p.parts):
            continue
        rel = p.relative_to(root)
        if any(str(rel).startswith(pfx) for pfx in _SKIP_PREFIXES):
            continue
        yield p


# ── checking logic ───────────────────────────────────────────────────


def _check_file(path, root):
    """Return list of (rel_path, line_no, escape, codepoint) tuples."""
    violations = []
    try:
        text = path.read_text(encoding="utf-8")
    except (UnicodeDecodeError, OSError) as exc:
        print(f"  WARNING: could not read {path.relative_to(root)}: {exc}")
        return violations

    for line_no, line in enumerate(text.splitlines(), 1):
        # Skip docstring regex examples
        if _is_docstring_regex_example(line):
            continue

        raw_spans = _raw_string_spans(line)

        for m in ESCAPE_RE.finditer(line):
            # Skip if inside a raw string
            if _in_raw_string(m.start(), raw_spans):
                continue

            cp = int(m.group(1), 16)
            if _should_be_literal(cp):
                violations.append((str(path.relative_to(root)), line_no, m.group(), cp))
    return violations


def main():
    root = Path(__file__).resolve().parent
    all_violations = []

    files = list(_tracked_files(root))
    for path in files:
        all_violations.extend(_check_file(path, root))

    if all_violations:
        print(f"FAIL: {len(all_violations)} unnecessary \\uXXXX escape(s) found:\n")
        for rel, line_no, esc, cp in all_violations:
            import unicodedata

            name = unicodedata.name(chr(cp), "?")
            print(f"  {rel}:{line_no}:  {esc}  →  {chr(cp)}  ({name})")
        print(
            f"\nRun fix_escape_sequences.py to replace these with literal characters."
        )
        return 1

    print(f"OK: no unnecessary \\uXXXX escapes in {len(files)} .py files.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
