# Initially generated by GitHub Copilot.
"""Search for words in cam1753 line-break data.

This module is parameterized: the caller supplies the line-break
directory and the book name, so the same logic can serve both the
one-off preview tool and the batch crop editor.
"""

import json
from pathlib import Path

from .hebrew_metrics import strip_heb

MAQAF = "\u05be"


def find_word_in_linebreaks(lb_dir, page_id, book, ch, v, consensus):
    """Find a word in line-break data.

    Parameters
    ----------
    lb_dir : Path
        Directory containing ``<page_id>.json`` line-break files.
    page_id : str or list[str]
        Page identifier (e.g. ``"0073A"``) or a list of page
        identifiers to search.  When a list is given, pages are tried
        in order and the first successful match is returned.  This
        handles verses that span a page boundary.
    book : str
        Book name used in verse labels (e.g. ``"Job"``).
    ch, v : int
        Chapter and verse numbers.
    consensus : str
        The target word (with or without accents/vowels).

    Returns
    -------
    tuple (col, line_num, word_index_in_line, line_words)
        ``col`` and ``line_num`` identify the line; ``word_index_in_line``
        is the 0-based word position; ``line_words`` lists every word on
        that line. All four are ``None``/empty on failure.

    When *page_id* is a list, the returned ``col`` / ``line_num`` are
    relative to whichever page contained the match.  The caller can
    determine the winning page from the return of
    :func:`find_pages_for_verse`.
    """
    if isinstance(page_id, (list, tuple)):
        return _find_word_multi_page(lb_dir, page_id, book, ch, v, consensus)
    lb_path = Path(lb_dir) / f"{page_id}.json"
    stream = json.loads(lb_path.read_text("utf-8"))

    verse_label = f"{book} {ch}:{v}"
    in_verse = False
    cur_col = cur_line = None
    consensus_stripped = strip_heb(consensus)
    consensus_has_maqaf = MAQAF in consensus

    target_col = target_line = None
    match_count = 0
    recent_words = []

    for item in stream:
        if isinstance(item, dict):
            if item.get("verse-start") == verse_label or \
               item.get("verse-fragment-start") == verse_label:
                in_verse = True
                recent_words = []
                continue
            if item.get("verse-end") == verse_label or \
               item.get("verse-fragment-end") == verse_label:
                in_verse = False
                continue
            if "line-start" in item:
                cur_col = item["line-start"]["col"]
                cur_line = item["line-start"]["line-num"]
                continue
        elif isinstance(item, str) and in_verse:
            item_stripped = strip_heb(item)
            matched = (
                item == consensus
                or item_stripped == consensus_stripped
                or (consensus.endswith(MAQAF)
                    and item_stripped == strip_heb(consensus[:-1]))
            )
            if matched:
                match_count += 1
                if match_count == 1:
                    target_col, target_line = cur_col, cur_line
                continue
            if consensus_has_maqaf:
                recent_words.append(item)
                joined = "".join(recent_words)
                if strip_heb(joined) == consensus_stripped or joined == consensus:
                    match_count += 1
                    if match_count == 1:
                        target_col, target_line = cur_col, cur_line
                    continue
                while recent_words and not consensus_stripped.startswith(
                    strip_heb("".join(recent_words))
                ):
                    recent_words.pop(0)

    if match_count > 1:
        raise ValueError(
            f"Ambiguous: {match_count} matches for {consensus!r} in "
            f"{verse_label} on page {page_id}"
        )
    if target_col is None:
        return None, None, None, []

    # Second pass: collect all words on the target line
    in_target = False
    line_words = []
    for item in stream:
        if isinstance(item, dict):
            if "line-start" in item:
                ls = item["line-start"]
                if ls["col"] == target_col and ls["line-num"] == target_line:
                    in_target = True
                    line_words = []
                continue
            if "line-end" in item and in_target:
                break
        elif isinstance(item, str) and in_target:
            line_words.append(item)

    # Find word index within the line
    target_idx = None
    for i, w in enumerate(line_words):
        if (w == consensus or strip_heb(w) == consensus_stripped
                or (consensus.endswith(MAQAF)
                    and strip_heb(w) == strip_heb(consensus[:-1]))):
            target_idx = i
            break
        if consensus_has_maqaf and w.endswith(MAQAF):
            joined = w
            for j in range(i + 1, len(line_words)):
                joined += line_words[j]
                if strip_heb(joined) == consensus_stripped or joined == consensus:
                    target_idx = i
                    break
                if not line_words[j].endswith(MAQAF):
                    break
            if target_idx is not None:
                break

    return target_col, target_line, target_idx, line_words


def _find_word_multi_page(lb_dir, page_ids, book, ch, v, consensus):
    """Try *find_word_in_linebreaks* on each page until the word is found."""
    for pid in page_ids:
        col, line_num, word_idx, line_words = find_word_in_linebreaks(
            lb_dir, pid, book, ch, v, consensus
        )
        if col is not None:
            return col, line_num, word_idx, line_words
    return None, None, None, []
