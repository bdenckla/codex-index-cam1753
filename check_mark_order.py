# Initially generated by GitHub Copilot.
"""
Check that every Hebrew word in tracked .py and .json files has the
project’s standard combining-mark order (SBL2):

    base letter → shin/sin dot → dagesh → rafeh → (everything else unchanged)

Uses ``give_std_mark_order`` from ``pycmn.uni_denorm`` (local copy
of book-of-job/pycmn).

A “Hebrew word” is any maximal run matched by the regex:

    WORD_RE = r"[\u0590-\u05ff\u034f\ufb1e]+"

i.e. one or more characters from the Hebrew block (U+0590–U+05FF),
plus Combining Grapheme Joiner (U+034F) and Varika (U+FB1E).  Words that
contain no Hebrew *letter* (U+05D0–U+05EA) are skipped.

Exit codes:
  0 – All files pass
  1 – One or more violations found
"""

import re
import sys
from pathlib import Path

from pycmn.uni_denorm import give_std_mark_order

# ── regex definitions ────────────────────────────────────────────────

# A "Hebrew word": maximal run of Hebrew-block chars + CGJ + Varika.
WORD_RE = re.compile(r"[\u0590-\u05FF\u034F\uFB1E]+")

# At least one Hebrew letter (alef through tav).
HAS_LETTER_RE = re.compile(r"[\u05D0-\u05EA]")


# ── file discovery ──────────────────────────────────────────────────

_SKIP_DIRS = {".venv", "__pycache__", ".novc", ".git", "node_modules"}


def _tracked_files(root):
    """Yield .py and .json paths under *root*, skipping non-tracked dirs."""
    for p in sorted(root.rglob("*")):
        if any(part in _SKIP_DIRS for part in p.parts):
            continue
        if p.is_file() and p.suffix in (".py", ".json"):
            yield p


# ── checking logic ──────────────────────────────────────────────────


def _check_file(path, root):
    """Return list of (rel_path, line_no, original, reordered) tuples."""
    violations = []
    try:
        text = path.read_text(encoding="utf-8")
    except (UnicodeDecodeError, OSError) as exc:
        print(f"  WARNING: could not read {path.relative_to(root)}: {exc}")
        return violations

    for line_no, line in enumerate(text.splitlines(), 1):
        for m in WORD_RE.finditer(line):
            word = m.group()
            if not HAS_LETTER_RE.search(word):
                continue
            fixed = give_std_mark_order(word)
            if fixed != word:
                violations.append((str(path.relative_to(root)), line_no, word, fixed))
    return violations


def main():
    root = Path(__file__).resolve().parent
    all_violations = []

    files = list(_tracked_files(root))
    for path in files:
        all_violations.extend(_check_file(path, root))

    if all_violations:
        print(f"FAIL: {len(all_violations)} word(s) with non-standard mark order:\n")
        for rel, line_no, orig, fixed in all_violations:
            # Show codepoint sequences for clarity.
            orig_cp = " ".join(f"U+{ord(c):04X}" for c in orig)
            fixed_cp = " ".join(f"U+{ord(c):04X}" for c in fixed)
            print(f"  {rel}:{line_no}")
            print(f"    original : {orig}  [{orig_cp}]")
            print(f"    expected : {fixed}  [{fixed_cp}]")
            print()
        return 1

    print(f"OK: all Hebrew words in {len(files)} files have standard mark order.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
